import asyncio
import os
import json
import re
from typing import List, Dict, Any, Optional, Tuple
from dotenv import load_dotenv
import pandas as pd
from langchain_core.messages import HumanMessage
from langchain_deepseek import ChatDeepSeek
import sys
# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from mcp_use_new import MCPAgent, MCPClient

# å¯¼å…¥PPTè§£æå™¨
from ppt_parser import PPTParser

# é…ç½®ç¯å¢ƒå˜é‡
os.environ["DEEPSEEK_API_KEY"] = "sk-9f92dd6f720b4cb0bb2820a0babb1643"

class PPTUpdateAgent:
    """PPTæ›´æ–°Agentï¼Œèƒ½å¤Ÿæ£€æµ‹PPTä¸­éœ€è¦æ›´æ–°çš„å†…å®¹å¹¶æœç´¢æœ€æ–°ä¿¡æ¯"""
    
    def __init__(self, config_file: str, llm_model: str = "deepseek-chat"):
        """åˆå§‹åŒ–Agent
        
        Args:
            config_file: MCPé…ç½®æ–‡ä»¶è·¯å¾„
            llm_model: ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹
        """
        self.config_file = config_file
        self.llm_model = llm_model
        self.client = None
        self.agent = None
        self.llm = None
        self.parser = None
        self.execution_log = []
        
    async def initialize(self):
        """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å’Œè¯­è¨€æ¨¡å‹"""
        print("ğŸš€ åˆå§‹åŒ–PPTæ›´æ–°Agent...")
        load_dotenv()
        
        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        self.client = MCPClient.from_config_file(self.config_file)
        
        # åˆ›å»ºè¯­è¨€æ¨¡å‹
        self.llm = ChatDeepSeek(model=self.llm_model)
        
        # åˆ›å»ºAgent
        self.agent = MCPAgent(
            llm=self.llm, 
            client=self.client, 
            max_steps=5,
            verbose=True
        )
        
        print("âœ… åˆå§‹åŒ–å®Œæˆ")
    
    def load_ppt(self, ppt_file: str) -> bool:
        """åŠ è½½PPTæ–‡ä»¶
        
        Args:
            ppt_file: PPTæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            self.parser = PPTParser(ppt_file)
            self.parser.parse()
            print(f"âœ… æˆåŠŸåŠ è½½PPTæ–‡ä»¶: {ppt_file}")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½PPTæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False
    
    async def analyze_content(self, content: str) -> Dict[str, Any]:
        """åˆ†æå†…å®¹å¹¶ç¡®å®šéœ€è¦æ›´æ–°çš„éƒ¨åˆ†
        
        Args:
            content: PPTä¸­çš„æ–‡æœ¬å†…å®¹
            
        Returns:
            éœ€è¦æ›´æ–°çš„å†…å®¹å’ŒåŸå› 
        """
        self._log_step("åˆ†æå†…å®¹", {"å†…å®¹é•¿åº¦": len(content)})
        
        from datetime import datetime

        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹PPTå†…å®¹ï¼Œæ‰¾å‡ºå…¶ä¸­å¯èƒ½éœ€è¦æ›´æ–°çš„æ–°é—»ã€æ•°æ®æˆ–äº‹å®ï¼Œè¯·æ³¨æ„ï¼Œç°åœ¨çš„æ—¶é—´æ˜¯{current_time}ï¼Œå†…å®¹å¦‚ä¸‹ï¼š
        
        {content}
        
        å¯¹äºæ¯ä¸€éƒ¨åˆ†ï¼Œè¯·åˆ¤æ–­ï¼š
        1. è¿™éƒ¨åˆ†å†…å®¹æ˜¯å¦åŒ…å«å¯èƒ½å·²ç»è¿‡æ—¶çš„æ–°é—»ã€æ•°æ®æˆ–äº‹å®ï¼Ÿ
        2. ä¸ºä»€ä¹ˆä½ è®¤ä¸ºå®ƒéœ€è¦æ›´æ–°ï¼Ÿï¼ˆä¾‹å¦‚ï¼šåŒ…å«è¿‡æ—¶çš„æ—¥æœŸã€æœ‰æ˜ç¡®çš„æ—¶é—´æ ‡è®°ã€æ¶‰åŠå¿«é€Ÿå˜åŒ–çš„é¢†åŸŸç­‰ï¼‰
        3. åº”è¯¥æœç´¢ä»€ä¹ˆå…³é”®è¯æ¥è·å–æœ€æ–°ä¿¡æ¯ï¼Ÿ
        4. è¿™éƒ¨åˆ†å†…å®¹åœ¨PPTä¸­çš„å“ªä¸ªä½ç½®ï¼Ÿï¼ˆå¦‚å¹»ç¯ç‰‡ç¼–å·ï¼‰
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        {{
            "éœ€è¦æ›´æ–°çš„éƒ¨åˆ†": [
                {{
                    "å†…å®¹": "åŸæ–‡ä¸­éœ€è¦æ›´æ–°çš„éƒ¨åˆ†",
                    "åŸå› ": "åˆ¤æ–­ä¸ºéœ€è¦æ›´æ–°çš„åŸå› ",
                    "æœç´¢å…³é”®è¯": "å»ºè®®çš„æœç´¢å…³é”®è¯",
                    "ä½ç½®": "åœ¨PPTä¸­çš„ä½ç½®ä¿¡æ¯"
                }}
            ]
        }}
        """
        
        response = await self.llm.ainvoke([HumanMessage(content=prompt)])
        
        # æå–JSONéƒ¨åˆ†
        json_match = re.search(r'```json\s*(.*?)\s*```', response.content, re.DOTALL)
        if json_match:
            json_content = json_match.group(1)
        else:
            json_content = response.content
            
        try:
            # å°è¯•è§£æJSON
            result = json.loads(json_content)
            self._log_step("åˆ†æç»“æœ", result)
            return result
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ™å°è¯•ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
            print("âš ï¸ æ— æ³•è§£æJSONï¼Œå°†å°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯")
            fallback_result = {"éœ€è¦æ›´æ–°çš„éƒ¨åˆ†": [{"å†…å®¹": content[:200], "åŸå› ": "æ— æ³•ç¡®å®šå…·ä½“åŸå› ", "æœç´¢å…³é”®è¯": "æœ€æ–°ä¿¡æ¯"}]}
            self._log_step("åˆ†æç»“æœï¼ˆå›é€€ï¼‰", fallback_result)
            return fallback_result
    
    async def search_latest_info(self, keywords: str) -> str:
        """ä½¿ç”¨MCPæœç´¢æœ€æ–°ä¿¡æ¯
        
        Args:
            keywords: æœç´¢å…³é”®è¯
            
        Returns:
            æœç´¢ç»“æœæ‘˜è¦
        """
        self._log_step("å¼€å§‹æœç´¢", {"å…³é”®è¯": keywords})
        
        from datetime import datetime

        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # æ„å»ºæœç´¢æŸ¥è¯¢
        query = f"""
        è¯·æœç´¢å…³äº"{keywords}"çš„æœ€æ–°ä¿¡æ¯ï¼Œç‰¹åˆ«æ³¨æ„ï¼š
        1. å¯»æ‰¾æœ€æ–°çš„æ•°æ®ã€æ–°é—»å’Œå‘å±•åŠ¨æ€
        2. ç¡®ä¿ä¿¡æ¯æ¥æºå¯é ï¼Œä¼˜å…ˆé€‰æ‹©å®˜æ–¹ç½‘ç«™ã€çŸ¥åæ–°é—»åª’ä½“ã€å­¦æœ¯è®ºæ–‡ç­‰
        3. è®°å½•ä¿¡æ¯çš„å‘å¸ƒæ—¥æœŸ
        4. æ€»ç»“ä¸»è¦è§‚ç‚¹å’Œæ•°æ®

        å½“å‰æ—¶é—´ï¼š{current_time}

        è¯·è¿”å›æœç´¢ç»“æœä»¥åŠä¿¡æ¯æ¥æºå’Œæ—¥æœŸã€‚
        """
        
        # ä½¿ç”¨MCP Agentè¿›è¡Œæœç´¢
        result = await self.agent.run(query, max_steps=5)
        
        self._log_step("æœç´¢ç»“æœ", {"ç»“æœé•¿åº¦": len(result)})
        return result
    
    async def generate_update(self, original_content: str, search_results: str) -> str:
        """ç”Ÿæˆæ›´æ–°å†…å®¹
        
        Args:
            original_content: åŸå§‹å†…å®¹
            search_results: æœç´¢ç»“æœ
            
        Returns:
            æ›´æ–°åçš„å†…å®¹
        """
        self._log_step("ç”Ÿæˆæ›´æ–°", {"åŸå†…å®¹é•¿åº¦": len(original_content), "æœç´¢ç»“æœé•¿åº¦": len(search_results)})
        
        prompt = f"""
        è¯·åŸºäºä»¥ä¸‹æœ€æ–°çš„æœç´¢ç»“æœï¼Œä¸ºPPTä¸­çš„å†…å®¹ç”Ÿæˆæ›´æ–°ï¼š
        
        åŸå§‹å†…å®¹ï¼š
        {original_content}
        
        æœ€æ–°æœç´¢ç»“æœï¼š
        {search_results}
        
        è¯·ç”Ÿæˆé€‚åˆåœ¨PPTä¸­å±•ç¤ºçš„æ›´æ–°å†…å®¹ï¼Œè¦æ±‚ï¼š
        1. ä¿æŒåŸæœ‰æ ¼å¼å’Œé£æ ¼ï¼Œä½†ä½¿ç”¨æœ€æ–°çš„æ•°æ®å’Œäº‹å®
        2. å†…å®¹åº”è¯¥ç®€æ´ã€æ¸…æ™°ï¼Œé€‚åˆPPTå±•ç¤º
        3. ä¸å…è®¸æœ‰'æ›´æ–°åçš„PPTå†…å®¹'ç­‰ä»‹ç»å†…å®¹ï¼Œåªèƒ½è¾“å‡ºå®è´¨æ€§å†…å®¹ï¼ï¼ä¸å…è®¸æœ‰ä»»ä½•ç¬¦å·ã€æ¢è¡Œç¬¦ç­‰
        4. ä¿æŒä¸åŸPPTçš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§
        """
        
        response = await self.llm.ainvoke([HumanMessage(content=prompt)])
        self._log_step("æ›´æ–°å†…å®¹", {"å†…å®¹é•¿åº¦": len(response.content)})
        return response.content
    
    async def process_slide(self, slide_index: int) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªå¹»ç¯ç‰‡
        
        Args:
            slide_index: å¹»ç¯ç‰‡ç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
            
        Returns:
            å¤„ç†ç»“æœ
        """
        if not self.parser:
            return {"é”™è¯¯": "è¯·å…ˆåŠ è½½PPTæ–‡ä»¶"}
        
        print(f"ğŸ” å¤„ç†å¹»ç¯ç‰‡ {slide_index}...")
        
        # è·å–å¹»ç¯ç‰‡å†…å®¹
        slide_content = self.parser.get_slide_text_content(slide_index)
        
        # åˆ†æå†…å®¹
        analysis = await self.analyze_content(slide_content)
        
        # å¤„ç†æ¯ä¸ªéœ€è¦æ›´æ–°çš„éƒ¨åˆ†
        updates = []
        for item in analysis.get("éœ€è¦æ›´æ–°çš„éƒ¨åˆ†", []):
            # æœç´¢æœ€æ–°ä¿¡æ¯
            search_result = await self.search_latest_info(item.get("æœç´¢å…³é”®è¯", ""))
            
            # ç”Ÿæˆæ›´æ–°å†…å®¹
            updated_content = await self.generate_update(item.get("å†…å®¹", ""), search_result)
            
            # è®°å½•æ›´æ–°
            updates.append({
                "åŸå†…å®¹": item.get("å†…å®¹", ""),
                "æ›´æ–°å†…å®¹": updated_content,
                "æœç´¢å…³é”®è¯": item.get("æœç´¢å…³é”®è¯", ""),
                "æœç´¢ç»“æœ": search_result
            })
        
        return {
            "å¹»ç¯ç‰‡": slide_index,
            "åˆ†æç»“æœ": analysis,
            "æ›´æ–°å†…å®¹": updates
        }
    
    async def process_ppt(self, ppt_file: str, slides: List[int] = None) -> Dict[str, Any]:
        """å¤„ç†æ•´ä¸ªPPT
        
        Args:
            ppt_file: PPTæ–‡ä»¶è·¯å¾„
            slides: è¦å¤„ç†çš„å¹»ç¯ç‰‡åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰å¹»ç¯ç‰‡
            
        Returns:
            å¤„ç†ç»“æœ
        """
        # é‡ç½®æ‰§è¡Œæ—¥å¿—
        self.execution_log = []
        
        # åŠ è½½PPT
        if not self.load_ppt(ppt_file):
            return {"é”™è¯¯": "åŠ è½½PPTå¤±è´¥"}
        
        # å¦‚æœæœªæŒ‡å®šå¹»ç¯ç‰‡ï¼Œåˆ™åˆ†ææ‰€æœ‰å¹»ç¯ç‰‡
        if slides is None:
            # è·å–æ‰€æœ‰PPTå†…å®¹
            all_content = self.parser.get_slide_text_content()
            
            # åˆ†æå†…å®¹æ‰¾å‡ºéœ€è¦æ›´æ–°çš„éƒ¨åˆ†
            analysis = await self.analyze_content(all_content)
            
            # ä»åˆ†æç»“æœä¸­æå–éœ€è¦å¤„ç†çš„å¹»ç¯ç‰‡
            slides_to_process = []
            for item in analysis.get("éœ€è¦æ›´æ–°çš„éƒ¨åˆ†", []):
                # å°è¯•ä»ä½ç½®ä¿¡æ¯ä¸­æå–å¹»ç¯ç‰‡ç¼–å·
                position = item.get("ä½ç½®", "")
                slide_match = re.search(r'å¹»ç¯ç‰‡\s*(\d+)', position)
                if slide_match:
                    slide_num = int(slide_match.group(1))
                    if slide_num not in slides_to_process:
                        slides_to_process.append(slide_num)
            
            # å¦‚æœæ— æ³•ç¡®å®šå…·ä½“å¹»ç¯ç‰‡ï¼Œåˆ™é»˜è®¤å¤„ç†å‰5å¼ 
            if not slides_to_process:
                slides_to_process = list(range(1, min(6, len(self.parser.slide_contents) + 1)))
        else:
            slides_to_process = slides
        
        # å¤„ç†é€‰å®šçš„å¹»ç¯ç‰‡
        print(f"ğŸ”„ å°†å¤„ç†ä»¥ä¸‹å¹»ç¯ç‰‡: {slides_to_process}")
        results = []
        for slide_index in slides_to_process:
            slide_result = await self.process_slide(slide_index)
            results.append(slide_result)
        
        return {
            "æ–‡ä»¶": ppt_file,
            "å¤„ç†çš„å¹»ç¯ç‰‡": slides_to_process,
            "ç»“æœ": results,
            "æ‰§è¡Œæ—¥å¿—": self.execution_log
        }
    
    def _log_step(self, action: str, data: Dict[str, Any] = None) -> None:
        """è®°å½•æ‰§è¡Œæ­¥éª¤
        
        Args:
            action: åŠ¨ä½œåç§°
            data: ç›¸å…³æ•°æ®
        """
        step = {
            "æ—¶é—´æˆ³": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
            "åŠ¨ä½œ": action,
            "æ•°æ®": data or {}
        }
        self.execution_log.append(step)
    
    async def close(self):
        """å…³é—­Agentå’Œå®¢æˆ·ç«¯è¿æ¥"""
        if self.agent:
            await self.agent.close()

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="PPTæ›´æ–°Agent")
    parser.add_argument("--ppt", help="PPTæ–‡ä»¶è·¯å¾„", required=True)
    parser.add_argument("--slides", help="è¦å¤„ç†çš„å¹»ç¯ç‰‡ç¼–å·åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š1,3,5", default=None)
    parser.add_argument("--config", help="MCPé…ç½®æ–‡ä»¶è·¯å¾„", default=None)
    parser.add_argument("--output", help="ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„", default=None)
    args = parser.parse_args()
    
    # å¤„ç†å‚æ•°
    ppt_file = args.ppt
    slides = [int(x) for x in args.slides.split(",")] if args.slides else None
    
    # è®¾ç½®é…ç½®æ–‡ä»¶è·¯å¾„
    if args.config:
        config_file = args.config
    else:
        config_file = os.path.join(os.path.dirname(__file__), "browser_mcp.json")
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
    if args.output:
        output_file = args.output
    else:
        output_file = os.path.splitext(ppt_file)[0] + "_update_report.json"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(ppt_file):
        print(f"é”™è¯¯: PPTæ–‡ä»¶ä¸å­˜åœ¨: {ppt_file}")
        return
    
    if not os.path.exists(config_file):
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    # åˆå§‹åŒ–Agent
    agent = PPTUpdateAgent(config_file)
    await agent.initialize()
    
    try:
        # å¤„ç†PPT
        print(f"ğŸ” å¼€å§‹å¤„ç†PPT: {ppt_file}")
        result = await agent.process_ppt(ppt_file, slides)
        
        # ä¿å­˜ç»“æœ
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ‰“å°æ‘˜è¦
        print("\nğŸ“Š å¤„ç†æ‘˜è¦:")
        print(f"- æ–‡ä»¶: {ppt_file}")
        print(f"- å¤„ç†çš„å¹»ç¯ç‰‡: {result.get('å¤„ç†çš„å¹»ç¯ç‰‡', [])}")
        
        update_count = 0
        for slide_result in result.get("ç»“æœ", []):
            update_count += len(slide_result.get("æ›´æ–°å†…å®¹", []))
        
        print(f"- æ‰¾åˆ°çš„æ›´æ–°é¡¹ç›®: {update_count}")
        print(f"- è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {output_file}")
        
    finally:
        # å…³é—­Agent
        await agent.close()

if __name__ == "__main__":
    asyncio.run(main()) 